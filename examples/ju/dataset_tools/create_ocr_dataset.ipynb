{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "241df2bb",
   "metadata": {},
   "source": [
    "# Docs\n",
    "\n",
    " * https://hsc.gov.ua/wp-content/uploads/2021/02/nomera-proekt-1.pdf\n",
    " * https://docs.dtkt.ua/download/pdf/1233.587.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3951ba91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/pkg_resources/__init__.py:123: PkgResourcesDeprecationWarning: 0.1.43ubuntu1 is an invalid version and will not be supported in a future release\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/pkg_resources/__init__.py:123: PkgResourcesDeprecationWarning: 1.1build1 is an invalid version and will not be supported in a future release\n",
      "  warnings.warn(\n",
      "/home/dimabendera/.local/lib/python3.10/site-packages/torch/cuda/__init__.py:83: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 803: system has unsupported display driver / cuda driver combination (Triggered internally at  ../c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import glob\n",
    "import cv2\n",
    "import json\n",
    "import string\n",
    "import tqdm\n",
    "import numpy as np\n",
    "from imutils.perspective import four_point_transform\n",
    "from skimage import exposure\n",
    "\n",
    "from skimage.io import imread, imshow\n",
    "from skimage import img_as_ubyte\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.exposure import histogram, cumulative_distribution\n",
    "from scipy.stats import cauchy, logistic\n",
    "\n",
    "import imutils\n",
    "from PIL import ImageFont, ImageDraw, Image\n",
    "from matplotlib import pyplot as plt\n",
    "from _paths import nomeroff_net_dir\n",
    "from nomeroff_net.tools import modelhub\n",
    "from collections import Counter\n",
    "import re\n",
    "import string\n",
    "\n",
    "import albumentations as A\n",
    "from nomeroff_net.tools.image_processing import get_cv_zone_rgb, distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b37b3093",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(image):\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b2e925b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (20,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6320e571",
   "metadata": {},
   "outputs": [],
   "source": [
    "info = modelhub.download_repo_for_model(\"yolov5\")\n",
    "repo_path = info[\"repo_path\"]\n",
    "\n",
    "# auto download latest dataset\n",
    "info = modelhub.download_dataset_for_model(\"yolov5\")\n",
    "PATH_TO_DATASET = info[\"dataset_path\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97bdeecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = PATH_TO_DATASET\n",
    "dataset = \"train\"\n",
    "json_data_path = \"train/via_region_data.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4bdbe582",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_formats = [\n",
    "    \"eu-ua-2015.png\",\n",
    "]\n",
    "path_to_images_example = os.path.join(nomeroff_net_dir, \n",
    "                                      \"data/dataset/OptionsDetector/numberplate_options_example/train/img/{}\")\n",
    "\n",
    "# images_formats = [\n",
    "#     os.path.basename(img_path)\n",
    "#     for img_path in glob.glob(os.path.join(PATH_TO_DATASET, \"../../../TextDetector/numberplate_sintetic/*\"))\n",
    "#     if cv2.imread(img_path).shape[:2] == (50, 235)\n",
    "# ]\n",
    "# path_to_images_example = os.path.join(nomeroff_net_dir, \n",
    "#                                       \"data/dataset/TextDetector/numberplate_sintetic/{}\")\n",
    "\n",
    "seria = [\n",
    "    \"AA\",\t\"BA\",\t\"CA\",\t\"EA\",\t\"HA\",\t\"IA\",\t\"KA\",\t\"MA\",\t\"OA\",\t\"PA\",\t\n",
    "    \"TA\",\t\"XA\",\t\"AB\",\t\"BB\",\t\"CB\",\t\"EB\",\t\"HB\",\t\"IB\",\t\"KB\",\t\"MB\",\t\n",
    "    \"OB\",\t\"PB\",\t\"TB\",\t\"XB\",\t\"AC\",\t\"BC\",\t\"CC\",\t\"EC\",\t\"HC\",\t\"IC\",\t\n",
    "    \"KC\",\t\"MC\",\t\"OC\",\t\"PC\",\t\"TC\",\t\"XC\",\t\"AE\",\t\"BE\",\t\"CE\",\t\"EE\",\t\n",
    "    \"HE\",\t\"IE\",\t\"KE\",\t\"ME\",\t\"OE\",\t\"PE\",\t\"TE\",\t\"XE\",\t\"AH\",\t\"BH\",\t\n",
    "    \"CH\",\t\"EH\",\t\"HH\",\t\"IH\",\t\"KH\",\t\"MH\",\t\"OH\",\t\"PH\",\t\"TH\",\t\"XH\",\t\n",
    "    \"AI\",\t\"BI\",\t\"CI\",\t\"EL\",\t\"HI\",\t\"II\",\t\"KI\",\t\"MI\",\t\"OI\",\t\"PI\",\t\n",
    "    \"TI\",\t\"XI\",\t\"AK\",\t\"BK\",\t\"CK\",\t\"EK\",\t\"HK\",\t\"IK\",\t\"KK\",\t\"MK\",\t\n",
    "    \"OK\",\t\"PK\",\t\"TK\",\t\"XK\",\t\"AM\",\t\"BM\",\t\"CM\",\t\"EM\",\t\"HM\",\t\"IM\",\t\n",
    "    \"KM\",\t\"MM\",\t\"OM\",\t\"PM\",\t\"TM\",\t\"XM\",\t\"AO\",\t\"BO\",\t\"CO\",\t\"EO\",\t\n",
    "    \"HO\",\t\"IO\",\t\"KO\",\t\"MO\",\t\"OO\",\t\"PO\",\t\"TO\",\t\"XO\",\t\"AP\",\t\"BP\",\t\n",
    "    \"CP\",\t\"EP\",\t\"HP\",\t\"IP\",\t\"KP\",\t\"MP\",\t\"OP\",\t\"PP\",\t\"TP\",\t\"XP\",\t\n",
    "    \"AT\",\t\"BT\",\t\"CT\",\t\"ET\",\t\"HT\",\t\"IT\",\t\"KT\",\t\"MT\",\t\"OT\",\t\"PT\",\t\n",
    "    \"TT\",\t\"XT\",\t\"AX\",\t\"BX\",\t\"CX\",\t\"EX\",\t\"HX\",\t\"IX\",\t\"KX\",\t\"MX\",\t\n",
    "    \"OX\",\t\"PX\",\t\"TX\",\t\"XX\",   \"YU\",\t\"YV\",\t\"YX\",\t\"YY\",\t\"YZ\",\n",
    "    \"XF\",\t\"XG\",\t\"XJ\",\t\"XL\",\t\"XN\",\t\"XR\",\t\"XS\",\t\"XU\",\t\"XV\",\t\n",
    "    \"XY\",\t\"XZ\",\t\"FF\",\t\"FG\",\t\"FJ\",\t\"FL\",\t\"FN\",\t\"FR\",\t\"FS\",\t\"FU\",\t\n",
    "    \"FV\",\t\"FY\",\t\"FZ\",\t\"AF\",\t\"AG\",\t\"AJ\",\t\"AL\",\t\"AN\",\t\"AR\",\t\n",
    "    \"AS\",\t\"AU\",\t\"AV\",\t\"TF\",\t\"TG\",\t\"TJ\",\t\"TL\",\t\"TN\",\t\"TR\",\t\n",
    "    \"TS\",\t\"TU\",\t\"TV\",\t\"TY\",\t\"TZ\",\t\"ZA\",\t\"ZB\",\t\"ZC\",\t\"ZD\",\t\n",
    "    \"ZE\",\t\"ZF\",\t\"ZG\",\t\"ZH\",\t\"ZI\",\t\"ZJ\",\t\"ZK\",\t\"ZL\",\t\"ZM\",\t\"ZN\",\t\n",
    "    \"ZO\",\t\"ZP\",\t\"ZR\",\t\"ZS\",\t\"ZT\",\t\"ZU\",\t\"ZV\",\t\"ZX\",\t\"ZY\",\t\n",
    "    \"ZZ\",\t\"YA\",\t\"YB\",\t\"YC\",\t\"YD\",\t\"YE\",\t\"YF\",\t\"YG\",\t\"YH\",\t\"YI\",\t\n",
    "    \"YJ\",\t\"YK\",\t\"YL\",\t\"YM\",\t\"YN\",\t\"YO\",\t\"YP\",\t\"YR\",\t\"YS\",\t\"YT\",\t\n",
    "    \"XW\",\t\"YW\",\t\"FW\",\t\"AW\",\t\"TW\",\t\"ZW\",\t\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b63afad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_files_np_formats = [\n",
    "    \"np_D.txt\",\n",
    "    \"np_F.txt\",\n",
    "    \"np_J.txt\",\n",
    "    \"np_Y.txt\",\n",
    "    \"np_z01012022_po01102022.txt\",\n",
    "]\n",
    "\n",
    "ascii_roman_map = {\n",
    "    \"А\": \"A\", \n",
    "    \"І\": \"I\", \n",
    "    \"В\": \"B\", \n",
    "    \"Е\": \"E\", \n",
    "    \"К\": \"K\", \n",
    "    \"М\": \"M\", \n",
    "    \"Н\": \"H\", \n",
    "    \"О\": \"O\", \n",
    "    \"Р\": \"P\", \n",
    "    \"С\": \"C\", \n",
    "    \"Т\": \"T\", \n",
    "    \"У\": \"Y\", \n",
    "    \"Х\": \"X\"\n",
    "}\n",
    "\n",
    "text_np_variants = []\n",
    "for txt_file_np_formats in txt_files_np_formats:\n",
    "    with open(f\"/var/www/nomeroff-net/data/dataset/TextDetector/{txt_file_np_formats}\") as fp:\n",
    "        lines = fp.readlines()\n",
    "        for line in lines:\n",
    "            line = \"\".join([ascii_roman_map.get(letter, letter) for letter in line])\n",
    "            g = re.search(f'[{string.ascii_uppercase}][{string.ascii_uppercase}][0-9][0-9][0-9][0-9][{string.ascii_uppercase}][{string.ascii_uppercase}]', line)\n",
    "            if g is None:\n",
    "                continue\n",
    "            else:\n",
    "                l = g.group(0)\n",
    "                if \"L\" in l:\n",
    "                    continue\n",
    "                if \"F\" in l and \"Y\" in l:\n",
    "                    text_np_variants.append(l)\n",
    "                if \"F\" in l and l[:2] not in set([text_np[:2] for text_np in text_np_variants if \"F\" in text_np]):\n",
    "                    text_np_variants.append(l)\n",
    "                if \"F\" in l and l[6:] not in set([text_np[6:] for text_np in text_np_variants if \"F\" in text_np]):\n",
    "                    text_np_variants.append(l)\n",
    "                if \"G\" in l:\n",
    "                    text_np_variants.append(l)\n",
    "                if \"D\" in l:\n",
    "                    for i in range(10):\n",
    "                        text_np_variants.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7fbaf97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'all': 1510, 'G': 775, 'D': 700, 'F': 35, 'J': 192, 'Y': 260})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter({\n",
    "    \"all\": len(text_np_variants),\n",
    "    \"G\": len([text_np for text_np in text_np_variants if \"G\" in text_np]),\n",
    "    \"D\": len([text_np for text_np in text_np_variants if \"D\" in text_np]),\n",
    "    \"F\": len([text_np for text_np in text_np_variants if \"F\" in text_np]),\n",
    "    \"J\": len([text_np for text_np in text_np_variants if \"J\" in text_np]),\n",
    "    \"Y\": len([text_np for text_np in text_np_variants if \"Y\" in text_np]),\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04fc605f",
   "metadata": {},
   "outputs": [],
   "source": [
    "seria = list(seria)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0bf5c154",
   "metadata": {},
   "outputs": [],
   "source": [
    "avaliable_letters = list(set(\"\".join(seria)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c856e676",
   "metadata": {},
   "source": [
    "# READ DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8dbbd390",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8411/8411 [00:00<00:00, 333783.93it/s]\n"
     ]
    }
   ],
   "source": [
    "res_datasets = {}\n",
    "res_datasets[dataset] = []\n",
    "\n",
    "with open(os.path.join(ROOT_DIR, json_data_path)) as jsonFile:\n",
    "    json_data = json.load(jsonFile)\n",
    "for key in tqdm.tqdm((json_data[\"_via_img_metadata\"])):\n",
    "    metadata = json_data[\"_via_img_metadata\"][key]\n",
    "\n",
    "    # define image_id\n",
    "    image_file_name = metadata[\"filename\"]\n",
    "    image_file_name = os.path.join(ROOT_DIR, dataset, image_file_name)\n",
    "    for region in metadata[\"regions\"]:\n",
    "        if region[\"shape_attributes\"].get(\"all_points_x\", None) is None or region[\"shape_attributes\"].get(\"all_points_y\", None) is None:\n",
    "            continue\n",
    "        np_zone = [(x, y) for x, y in zip(region[\"shape_attributes\"][\"all_points_x\"], region[\"shape_attributes\"][\"all_points_y\"])]\n",
    "        res_datasets[dataset].append([image_file_name, np_zone])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94dcdba1",
   "metadata": {},
   "source": [
    "# TOOLS FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f7696dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def order_points(pts):\n",
    "    # initialzie a list of coordinates that will be ordered\n",
    "    # such that the first entry in the list is the top-left,\n",
    "    # the second entry is the top-right, the third is the\n",
    "    # bottom-right, and the fourth is the bottom-left\n",
    "    rect = np.zeros((4, 2), dtype = \"float32\")\n",
    "    # the top-left point will have the smallest sum, whereas\n",
    "    # the bottom-right point will have the largest sum\n",
    "    s = pts.sum(axis = 1)\n",
    "    rect[0] = pts[np.argmin(s)]\n",
    "    rect[2] = pts[np.argmax(s)]\n",
    "    # now, compute the difference between the points, the\n",
    "    # top-right point will have the smallest difference,\n",
    "    # whereas the bottom-left will have the largest difference\n",
    "    diff = np.diff(pts, axis = 1)\n",
    "    rect[1] = pts[np.argmin(diff)]\n",
    "    rect[3] = pts[np.argmax(diff)]\n",
    "    # return the ordered coordinates\n",
    "    return rect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cadf58bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_linear_cdf(image, channel, name, ax):\n",
    "    image_intensity = img_as_ubyte(image[:,:,channel])\n",
    "    freq, bins = cumulative_distribution(image_intensity)\n",
    "    target_bins = np.arange(255)\n",
    "    target_freq = np.linspace(0, 1, len(target_bins))\n",
    "    ax.step(bins, freq, c='b', label='Actual CDF')\n",
    "    ax.plot(target_bins, target_freq, c='r', label='Target CDF')\n",
    "    ax.legend()\n",
    "    ax.set_title('{} Channel: Actual vs. '\n",
    "                 'Target Cumulative Distribution'.format(name))\n",
    "\n",
    "def linear_distribution(image, channel):\n",
    "    image_intensity = img_as_ubyte(image[:,:,channel])\n",
    "    freq, bins = cumulative_distribution(image_intensity)\n",
    "    target_bins = np.arange(255)\n",
    "    target_freq = np.linspace(0, 1, len(target_bins))\n",
    "    new_vals = np.interp(freq, target_freq, target_bins)\n",
    "    return new_vals[image_intensity].astype(np.uint8)\n",
    "\n",
    "\n",
    "def individual_channel(image, dist, channel):\n",
    "    im_channel = img_as_ubyte(image[:,:,channel])\n",
    "    freq, bins = cumulative_distribution(im_channel)\n",
    "    new_vals = np.interp(freq, dist.cdf(np.arange(0,256)), \n",
    "                               np.arange(0,256))\n",
    "    return new_vals[im_channel].astype(np.uint8)\n",
    "\n",
    "\n",
    "def distribution(image, function, mean, std):\n",
    "    dist = function(mean, std)\n",
    "    image_intensity = img_as_ubyte(rgb2gray(image))\n",
    "    freq, bins = cumulative_distribution(image_intensity)\n",
    "    red = individual_channel(image, dist, 0)\n",
    "    green = individual_channel(image, dist, 1)\n",
    "    blue = individual_channel(image, dist, 2)\n",
    "    corrected_image = np.dstack((red, green, blue))\n",
    "    return corrected_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d250f5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_img():\n",
    "    random_i = random.randint(0, len(res_datasets[dataset]) - 1)\n",
    "    fake_img_path, fake_np_four_points = res_datasets[dataset][random_i]\n",
    "\n",
    "    fake_img = cv2.imread(fake_img_path)[:,:,::-1]\n",
    "    fake_img = np.concatenate((fake_img, 255*np.ones((*fake_img.shape[:2], 1))), axis=2)\n",
    "    ordered_p_fake = order_points(np.array(fake_np_four_points, dtype = \"float32\"))\n",
    "\n",
    "    return fake_img, ordered_p_fake\n",
    "\n",
    "\n",
    "def draw_fake(img, fake_img, ordered_p_fake):\n",
    "    ordered_p_orig = np.array([(0, 0), \n",
    "                               (img.shape[1], 0), \n",
    "                               (img.shape[1], img.shape[0]), \n",
    "                               (0, img.shape[0])], dtype = \"float32\")\n",
    "    \n",
    "\n",
    "    M = cv2.getPerspectiveTransform(ordered_p_orig, \n",
    "                                    ordered_p_fake)\n",
    "    warped = cv2.warpPerspective(img, M, (fake_img.shape[1], fake_img.shape[0]))\n",
    "    cntrs = ordered_p_fake.reshape(1, ordered_p_fake.shape[0], ordered_p_fake.shape[1]).astype(np.int32)\n",
    "\n",
    "    stencil = np.zeros(warped.shape).astype(warped.dtype)\n",
    "    contours = cntrs\n",
    "    \n",
    "    cv2.fillPoly(stencil, contours, [255, 255, 255])\n",
    "    np_mask = cv2.bitwise_and(warped, stencil)\n",
    "    \n",
    "    overlay_img1 = np.ones(fake_img.shape, np.uint8)*255\n",
    "    \n",
    "    rows, cols, channels = np_mask.shape\n",
    "    overlay_img1[:, :] = warped\n",
    "    img2gray = cv2.cvtColor(overlay_img1, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    ret, mask = cv2.threshold(img2gray, 1, 255, cv2.THRESH_BINARY)\n",
    "        \n",
    "    mask_inv = cv2.bitwise_not(mask)\n",
    "\n",
    "    fake_img = fake_img.astype(np.uint8)\n",
    "    temp1 = cv2.bitwise_and(fake_img, fake_img, mask = mask_inv)\n",
    "    temp2 = cv2.bitwise_and(overlay_img1, overlay_img1, mask = mask)\n",
    "    \n",
    "    temp1 = temp1.astype(np.uint8)\n",
    "    fake_np_img = cv2.add(temp1, temp2)\n",
    "    return fake_np_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "68b6aa12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def domain_adoptation(src, trg, freq):\n",
    "\n",
    "    \"\"\"\n",
    "    Parameters: \n",
    "    src - source image, which style has to be changed\n",
    "    trg - target image, which low-frequency domain will be adopted\n",
    "    freq - number of frequencies to be used\n",
    "\n",
    "    Returns:\n",
    "    result - np.array based on srs image (shape and high frequencies) \n",
    "         with low frequencies of the target image\n",
    "    \"\"\"\n",
    "\n",
    "    result = np.zeros((src.shape[0],src.shape[1],src.shape[2]))\n",
    "\n",
    "    for i in range(src.shape[2]):\n",
    "        trg_fft = np.fft.fft2(trg[:,:,i])\n",
    "        src_fft = np.fft.fft2(src[:,:,i])\n",
    "\n",
    "        trg_fft_shift = np.fft.fftshift(trg_fft)\n",
    "        src_fft_shift = np.fft.fftshift(src_fft)\n",
    "\n",
    "        src_fft_shift[src.shape[0]//2-freq:src.shape[0]//2+freq,\n",
    "                         src.shape[1]//2-freq:src.shape[1]//2+freq] = \\\n",
    "            trg_fft_shift[trg.shape[0]//2-freq:trg.shape[0]//2+freq,\n",
    "                           trg.shape[1]//2-freq:trg.shape[1]//2+freq]\n",
    "\n",
    "        src_ifft_shift = np.fft.ifftshift(src_fft_shift)\n",
    "\n",
    "        result[:,:,i] = np.fft.ifft2(src_ifft_shift)\n",
    "        result[:,:,i] = np.abs(result[:,:,i])\n",
    "\n",
    "    result = np.float32(result)\n",
    "    result = cv2.cvtColor(result, cv2.COLOR_BGR2RGB)\n",
    "    result = cv2.normalize(result,None,0,1,cv2.NORM_MINMAX)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "78e4030f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_transfer(source, target):\n",
    "    source = cv2.resize(source, (target.shape[1], target.shape[0]))\n",
    "    # convert the images from the RGB to L*ab* color space, being\n",
    "    # sure to utilizing the floating point data type (note: OpenCV\n",
    "    # expects floats to be 32-bit, so use that instead of 64-bit)\n",
    "    source = cv2.cvtColor(source, cv2.COLOR_BGR2LAB).astype(\"float32\")\n",
    "    target = cv2.cvtColor(target, cv2.COLOR_BGR2LAB).astype(\"float32\")\n",
    "    # compute color statistics for the source and target images\n",
    "    (lMeanSrc, lStdSrc, aMeanSrc, aStdSrc, bMeanSrc, bStdSrc) = image_stats(source)\n",
    "    (lMeanTar, lStdTar, aMeanTar, aStdTar, bMeanTar, bStdTar) = image_stats(target)\n",
    "    # subtract the means from the target image\n",
    "    (l, a, b) = cv2.split(target)\n",
    "    l -= lMeanTar\n",
    "    a -= aMeanTar\n",
    "    b -= bMeanTar\n",
    "    # scale by the standard deviations\n",
    "    l = (lStdTar / lStdSrc) * l\n",
    "    a = (aStdTar / aStdSrc) * a\n",
    "    b = (bStdTar / bStdSrc) * b\n",
    "    # add in the source mean\n",
    "    l += lMeanSrc\n",
    "    a += aMeanSrc\n",
    "    b += bMeanSrc\n",
    "    # clip the pixel intensities to [0, 255] if they fall outside\n",
    "    # this range\n",
    "    l = np.clip(l, 0, 255)\n",
    "    a = np.clip(a, 0, 255)\n",
    "    b = np.clip(b, 0, 255)\n",
    "    # merge the channels together and convert back to the RGB color\n",
    "    # space, being sure to utilize the 8-bit unsigned integer data\n",
    "    # type\n",
    "    transfer = cv2.merge([l, a, b])\n",
    "    transfer = cv2.cvtColor(transfer.astype(\"uint8\"), cv2.COLOR_LAB2BGR)\n",
    "\n",
    "    # return the color transferred image\n",
    "    return transfer\n",
    "\n",
    "\n",
    "def image_stats(image):\n",
    "    # compute the mean and standard deviation of each channel\n",
    "    (l, a, b) = cv2.split(image)\n",
    "    (lMean, lStd) = (l.mean(), l.std())\n",
    "    (aMean, aStd) = (a.mean(), a.std())\n",
    "    (bMean, bStd) = (b.mean(), b.std())\n",
    "    # return the color statistics\n",
    "    return (lMean, lStd, aMean, aStd, bMean, bStd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6da53603",
   "metadata": {},
   "outputs": [],
   "source": [
    "BOX_COLOR = (255, 0, 0) # Red\n",
    "TEXT_COLOR = (255, 255, 255) # White\n",
    "\n",
    "\n",
    "def visualize_bbox(img, bbox, color=BOX_COLOR, thickness=2, **kwargs):\n",
    "    x_min, y_min, w, h = bbox\n",
    "    x_min, x_max, y_min, y_max = int(x_min), int(x_min + w), int(y_min), int(y_min + h)\n",
    "    cv2.rectangle(img, (x_min, y_min), (x_max, y_max), color=color, thickness=thickness)\n",
    "    return img\n",
    "\n",
    "def visualize_titles(img, bbox, title, color=BOX_COLOR, thickness=2, font_thickness = 2, font_scale=0.35, **kwargs):\n",
    "    x_min, y_min, w, h = bbox\n",
    "    x_min, x_max, y_min, y_max = int(x_min), int(x_min + w), int(y_min), int(y_min + h)\n",
    "    ((text_width, text_height), _) = cv2.getTextSize(title, cv2.FONT_HERSHEY_SIMPLEX, font_scale, font_thickness)\n",
    "    cv2.rectangle(img, (x_min, y_min - int(1.3 * text_height)), (x_min + text_width, y_min), BOX_COLOR, -1)\n",
    "    cv2.putText(img, title, (x_min, y_min - int(0.3 * text_height)), cv2.FONT_HERSHEY_SIMPLEX, font_scale, TEXT_COLOR,\n",
    "                font_thickness, lineType=cv2.LINE_AA)\n",
    "    return img\n",
    "\n",
    "\n",
    "def augment_and_show(aug, image, filename=None, \n",
    "                     font_scale_orig=0.35, font_scale_aug=0.35, show=True, **kwargs):\n",
    "\n",
    "    augmented = aug(image=image)\n",
    "\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image_aug = cv2.cvtColor(augmented['image'], cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    if show:\n",
    "        f, ax = plt.subplots(1, 2, figsize=(16, 8))\n",
    "        ax[0].imshow(image)\n",
    "        ax[0].set_title('Original image')\n",
    "        ax[1].imshow(image_aug)\n",
    "        ax[1].set_title('Augmented image')\n",
    "        f.tight_layout()\n",
    "\n",
    "        if filename is not None:\n",
    "            f.savefig(filename)\n",
    "        \n",
    "    return augmented['image']\n",
    "\n",
    "def find_in_dir(dirname):\n",
    "    return [os.path.join(dirname, fname) for fname in sorted(os.listdir(dirname))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "91aa2bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_and_aug_numbeplate(np_img, ordered_p_fake):\n",
    "    l = np.random.uniform(0.01, 0.06)\n",
    "    np_img = np_img[:,:,:3].astype(np.uint8)\n",
    "    #print(np_img.shape)\n",
    "    # img_np = cv2.polylines(np_img, [ordered_p_fake.reshape((-1, 1, 2)).astype(np.int32)], True, (255, 0, 255), 2)\n",
    "    \n",
    "    d1 = (distance(ordered_p_fake[0], ordered_p_fake[1])+distance(ordered_p_fake[3], ordered_p_fake[3]))/2*l\n",
    "    d2 = (distance(ordered_p_fake[1], ordered_p_fake[2])+distance(ordered_p_fake[3], ordered_p_fake[0]))/2*l\n",
    "    ordered_p_fake[0,0] -= d1\n",
    "    ordered_p_fake[1,0] += d1\n",
    "    ordered_p_fake[2,0] += d1\n",
    "    ordered_p_fake[3,0] -= d1\n",
    "    \n",
    "    ordered_p_fake[1,1] -= d2\n",
    "    ordered_p_fake[2,1] += d2\n",
    "    ordered_p_fake[0,1] -= d2\n",
    "    ordered_p_fake[3,1] += d2\n",
    "    img_np = get_cv_zone_rgb(np_img, ordered_p_fake)\n",
    "    \n",
    "    light = A.Compose([\n",
    "        A.RandomBrightnessContrast(p=1),    \n",
    "        A.RandomGamma(p=1),    \n",
    "        A.CLAHE(p=1),\n",
    "        A.Blur(),\n",
    "        A.GaussNoise(),\n",
    "        A.ShiftScaleRotate(shift_limit=0.01, scale_limit=0.01, rotate_limit=2, p=.75),\n",
    "    ], p=5)\n",
    "\n",
    "    \n",
    "    # img_np = cv2.polylines(np_img, [ordered_p_fake.reshape((-1, 1, 2)).astype(np.int32)], True, (0, 255, 255), 2)\n",
    "    return augment_and_show(light, img_np, show=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "18277023",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_fake_numberplate(img, \n",
    "                          b: int = 20, g: int = 56, r: int = 0, a: int = 255,\n",
    "                          draw_text=True,\n",
    "                          draw_numbers=True,\n",
    "                          text_color=\"#143800\"):\n",
    "    # FONT\n",
    "    fontpath = os.path.join(nomeroff_net_dir, \"data/font/186-font.otf\")\n",
    "    font = ImageFont.truetype(fontpath, 43)\n",
    "    number_fontpath = os.path.join(nomeroff_net_dir, \"data/font/3827-font.otf\")\n",
    "    number_font = ImageFont.truetype(number_fontpath, 48)\n",
    "    \n",
    "    img = img.copy()\n",
    "    img.thumbnail((235, 51))\n",
    "    \n",
    "    poly_w = 0\n",
    "    while poly_w < 100:\n",
    "        random_img, ordered_p_fake = get_random_img()\n",
    "        poly_w = distance(ordered_p_fake[0], ordered_p_fake[1])\n",
    "    \n",
    "    random_img = random_img.astype(np.uint8)\n",
    "    \n",
    "    #print(ordered_p_fake)\n",
    "    random_img_np = get_cv_zone_rgb(random_img, ordered_p_fake)\n",
    "#     print(\"random_img_np\", np.mean(random_img_np[:,:,:3]), np.max(random_img_np[:,:,:3]), \n",
    "#           np.min(random_img_np[:,:,:3]))\n",
    "#     plt.imshow(random_img_np)\n",
    "#     plt.show()\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    \n",
    "    numberpalte = random.choice(text_np_variants)\n",
    "    numberpalte = numberpalte[:2] + \"\".join(random.choices(string.digits, k=4)) \\\n",
    "                                       + numberpalte[-2:]\n",
    "    x_left_margin = 6\n",
    "    x_s = 27 + ((200 - (draw.textsize(numberpalte[:2], font)[0] + x_left_margin\n",
    "                     + draw.textsize(numberpalte[2:6], number_font)[0] + x_left_margin\n",
    "                     + draw.textsize(numberpalte[6:], font)[0])))/2\n",
    "    \n",
    "    #print(\"x_s\", x_s)\n",
    "    draw.rectangle([(28, 5), (226, 42)], fill =\"white\", outline =\"white\")\n",
    "    if draw_text:\n",
    "        draw.text((x_s, 8), numberpalte[:2], font = font, fill = (b, g, r, a))\n",
    "        x_s += draw.textsize(numberpalte[:2], font)[0] + x_left_margin\n",
    "    if draw_numbers:\n",
    "        draw.text((x_s, 4), numberpalte[2:6], font = number_font, fill = (b, g, r, a))\n",
    "        x_s += draw.textsize(numberpalte[2:6], number_font)[0] + x_left_margin\n",
    "    else:\n",
    "        x_s = 175.5\n",
    "    if draw_text:\n",
    "        draw.text((x_s, 8), numberpalte[6:], font = font, fill = (b, g, r, a))\n",
    "    \n",
    "    img = np.array(img)\n",
    "#     print(\"orig color\", np.mean(img[:,:,:3]), np.max(img[:,:,:3]), np.min(img[:,:,:3]))\n",
    "#     plt.imshow(img)\n",
    "#     plt.show()\n",
    "    \n",
    "    img[:,:,:3] = color_transfer(random_img_np, img[:,:,:3])\n",
    "    # \"speckle\", \"poisson\", \"s&p\",  \"gauss\"\n",
    "    #img[:,:,:3] = noisy(\"gauss\", img[:,:,:3])\n",
    "    #img[:,:,:3] = domain_adoptation(src=img[:,:,:3], trg=random_img_np, freq=1)\n",
    "    #img[:,:,:3] = distribution(img[:,:,:3], cauchy,  np.mean(random_img), np.mean(random_img)+90)\n",
    "    \n",
    "#     print(\"color corrected\", np.mean(img[:,:,:3]), np.min(img[:,:,:3]), np.max(img[:,:,:3]))\n",
    "#     plt.imshow(img)\n",
    "#     plt.show()\n",
    "    \n",
    "    fake_img = draw_fake(img, random_img, ordered_p_fake)\n",
    "    return fake_img, img, numberpalte, ordered_p_fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4de286",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▏                                                                                                                                                                  | 15/11000 [00:01<21:58,  8.33it/s]/tmp/ipykernel_150740/1468369858.py:17: RuntimeWarning: divide by zero encountered in float_scalars\n",
      "  l = (lStdTar / lStdSrc) * l\n",
      "/tmp/ipykernel_150740/1468369858.py:18: RuntimeWarning: divide by zero encountered in float_scalars\n",
      "  a = (aStdTar / aStdSrc) * a\n",
      "/tmp/ipykernel_150740/1468369858.py:19: RuntimeWarning: divide by zero encountered in float_scalars\n",
      "  b = (bStdTar / bStdSrc) * b\n",
      " 47%|███████████████████████████████████████████████████████████████████████████▏                                                                                     | 5140/11000 [13:24<11:22,  8.58it/s]"
     ]
    }
   ],
   "source": [
    "n = 11000\n",
    "RES_DIR = os.path.join(PATH_TO_DATASET, f\"../../../TextDetector/EuUaFrom2004Generated{n}\")\n",
    "res_dir_img = os.path.join(RES_DIR, \"img\")\n",
    "res_dir_ann = os.path.join(RES_DIR, \"ann\")\n",
    "\n",
    "os.makedirs(res_dir_img, exist_ok=True)\n",
    "os.makedirs(res_dir_ann, exist_ok=True)\n",
    "for i in tqdm.tqdm(range(n), total=n):\n",
    "    #np.random.shuffle(images_formats)\n",
    "    for image_format in images_formats:\n",
    "        #print(path_to_images_example.format(image_format))\n",
    "        img = Image.open(path_to_images_example.format(image_format))\n",
    "        gen_img, img_crop, numberplate, np_points = draw_fake_numberplate(img)\n",
    "        #print(numberplate, img.size)\n",
    "        np_img = crop_and_aug_numbeplate(gen_img, np_points)\n",
    "        # WTF? (when some not correct values image backome a one color image )\n",
    "        if np.max(np_img[:,:,0]) - np.min(np_img[:,:,0]) > 50 \\\n",
    "               or np.max(np_img[:,:,1]) - np.min(np_img[:,:,1]) > 50 \\\n",
    "               or np.max(np_img[:,:,2]) - np.min(np_img[:,:,2]) > 50:\n",
    "            cv2.imwrite(os.path.join(res_dir_img, f\"{i}_{numberplate}.png\"), np_img[:,:,::-1])\n",
    "            with open(os.path.join(res_dir_ann, f\"{i}_{numberplate}.json\"), \"w\") as fp:\n",
    "                json.dump({\n",
    "                    \"tags\":[],\n",
    "                    \"objects\":[],\n",
    "                    \"state_id\":\"2\",\n",
    "                    \"region_id\":\"1\",\n",
    "                    \"size\":{\"width\": np_img.shape[0], \"height\": np_img.shape[1]},\n",
    "                    \"moderation\":{\"isModerated\":1,\"moderatedBy\":\"autogen\",\"predicted\": numberplate},\n",
    "                    \"description\": numberplate,\n",
    "                    \"name\": f\"{i}_{numberplate}\",\n",
    "                    \"count_lines\": \"1\"}, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7958e18a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
